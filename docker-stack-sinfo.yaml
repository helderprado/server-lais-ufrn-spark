version: "3.7"

x-minio-common: &minio-common
  image: quay.io/minio/minio:RELEASE.2023-02-22T18-23-45Z
  command: server --console-address ":9001" http://minio{1...4}/data{1...2}
  environment:
    - MINIO_ROOT_USER=admin
    - MINIO_ROOT_PASSWORD=sample_key
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
    interval: 30s
    timeout: 20s
    retries: 3
  networks:
    - server

services:
  # JUPYTER SETTINGS

  jupyterhub:
    image: helderprado/jupyterhub-stack-server
    hostname: jupyterhub
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jupyterhub_data:/srv/jupyterhub
      - ./jupyterhub/jupyterhub_config.py:/srv/jupyterhub/jupyterhub_config.py
    environment:
      - DOCKER_JUPYTER_IMAGE=jupyter/all-spark-notebook:spark-3.3.0
      - DOCKER_NETWORK_NAME=server_server
      - HUB_IP=jupyterhub
      - JUPYTER_ENABLE_LAB="yes"
      - PYSPARK_SUBMIT_ARGS= --master spark://spark-master:7077 --packages com.amazonaws:aws-java-sdk-bundle:1.11.819,org.apache.hadoop:hadoop-aws:3.2.3 pyspark-shell
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=sample_key
      - MLFLOW_S3_ENDPOINT_URL=http://minio1:9000
    labels:
      - "traefik.enable=true"
      - "traefik.frontend.rule=Host:localhost"
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  # SPARK SETTINGS

  # MASTER

  spark-master:
    image: helderprado/spark-stack-server
    hostname: spark-master
    ports:
      - "7077:7077"
      - "9090:8080"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  # WORKER A

  spark-worker-a:
    hostname: spark-worker-a
    image: helderprado/spark-stack-server
    ports:
      - "9091:8080"
      - "7000:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8GB
      - SPARK_DRIVER_MEMORY=8GB
      - SPARK_EXECUTOR_MEMORY=8GB
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  # WORKER B

  # spark-worker-b:
  #   hostname: spark-worker-b
  #   image: helderprado/spark-stack-server
  #   ports:
  #     - "9092:8080"
  #     - "7001:7000"
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MASTER=spark://spark-master:7077
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_WORKER_MEMORY=4GB
  #     - SPARK_DRIVER_MEMORY=4GB
  #     - SPARK_EXECUTOR_MEMORY=4GB
  #     - SPARK_WORKLOAD=worker
  #     - SPARK_LOCAL_IP=spark-worker-b
  #   networks:
  #     - server
  # deploy:
  #   mode: replicated
  #   replicas: 1
  #   placement:
  #     constraints:
  #       - node.hostname == node2.lais.ufrn.br

  # # WORKER C

  # spark-worker-c:
  #   hostname: spark-worker-c
  #   image: helderprado/spark-stack-server
  #   ports:
  #     - "9093:8080"
  #     - "7002:7000"
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MASTER=spark://spark-master:7077
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_WORKER_MEMORY=2GB
  #     - SPARK_DRIVER_MEMORY=2GB
  #     - SPARK_EXECUTOR_MEMORY=2GB
  #     - SPARK_WORKLOAD=worker
  #     - SPARK_LOCAL_IP=spark-worker-c
  #   volumes:
  #     - jupyterhub_data:/home/jovyan/work:rw
  #   networks:
  #     - server
  # deploy:
  #   mode: replicated
  #   replicas: 1
  #   placement:
  #     constraints:
  #       - node.hostname == node3.lais.ufrn.br

  # # MLFLOW

  # mlflow:
  #   image: helderprado/mlflow-stack-server
  #   ports:
  #     - "5000:5000"
  #   environment:
  #     - AWS_ACCESS_KEY_ID=admin
  #     - AWS_SECRET_ACCESS_KEY=sample_key
  #     - AWS_DEFAULT_REGION=us-east-1
  #     - MLFLOW_S3_ENDPOINT_URL=http://minio1:9000
  #   entrypoint: bash ./wait-for-it.sh db:3306 -t 90 -- mlflow server --backend-store-uri mysql+pymysql://mlflow_user:mlflow_password@db:3306/mlflow --default-artifact-root s3://mlflow/ -h 0.0.0.0
  #   networks:
  #     - server
  #   deploy:
  #     mode: replicated
  #     replicas: 1
  #     placement:
  #       constraints:
  #         - node.hostname == helder-linux

  # ### BANCOS DE DADOS ################################

  # db:
  #   image: mysql/mysql-server:5.7.28
  #   environment:
  #     - MYSQL_DATABASE=mlflow
  #     - MYSQL_USER=mlflow_user
  #     - MYSQL_PASSWORD=mlflow_password
  #     - MYSQL_ROOT_PASSWORD=toor
  #   volumes:
  #     - db_volume:/var/lib/mysql
  #   networks:
  #     - server
  #   deploy:
  #     mode: replicated
  #     replicas: 1
  #     placement:
  #       constraints:
  #         - node.hostname == helder-linux

  lais-database:
    hostname: lais-database
    image: postgres:13-alpine
    volumes:
      - ./db/database.sql:/docker-entrypoint-initdb.d/database.sql
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: db
    ports:
      - "15433:5432"
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  postgres:
    image: postgres:9.6
    ports:
      - "15432:5432"
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow_db:/var/lib/postgresql/data
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  ### PROXY REVERSO #################################

  nginx:
    image: nginx:1.19.2-alpine
    hostname: nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "19000:9000"
      - "19001:9001"
    networks:
      - server
    # deploy:
    #   mode: global

  reverse-proxy:
    image: traefik:v1.7.16
    hostname: reverse-proxy
    ports:
      - "80:80"
      - "443:443"
      - "18080:8080"
    volumes:
      - ./reverse-proxy/traefik.toml:/etc/traefik/traefik.toml
      - ./reverse-proxy/certs:/etc/certs
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - server
    # deploy:
    #   mode: global

  # # AIRFLOW SETTINGS

  airflow-webserver:
    hostname: airflow-webserver
    image: helderprado/airflow-stack-server
    depends_on:
      - postgres
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=sample_key
      - AWS_DEFAULT_REGION=us-east-1
      - PYSPARK_SUBMIT_ARGS= --master spark://spark-master:7077 --packages com.amazonaws:aws-java-sdk-bundle:1.11.819,org.apache.hadoop:hadoop-aws:3.2.3 pyspark-shell
      - MLFLOW_S3_ENDPOINT_URL=http://minio1:9000
      - DUMP_POSTGRES_USER=postgres
      - DUMP_POSTGRES_PASSWORD=postgres
      - DUMP_POSTGRES_DB=db
    volumes:
      - type: volume
        source: nfs-data
        target: /usr/local/airflow/dags
        volume:
          nocopy: true
    ports:
      - "8282:8282"
    command: webserver
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  minio1:
    <<: *minio-common
    hostname: minio1
    volumes:
      - data1-1:/data1
      - data1-2:/data2
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  minio2:
    <<: *minio-common
    hostname: minio2
    volumes:
      - data2-1:/data1
      - data2-2:/data2
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  minio3:
    <<: *minio-common
    hostname: minio3
    volumes:
      - data3-1:/data1
      - data3-2:/data2
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  minio4:
    <<: *minio-common
    hostname: minio4
    volumes:
      - data4-1:/data1
      - data4-2:/data2
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  agent:
    image: portainer/agent
    environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      AGENT_CLUSTER_ADDR: tasks.agent
      # AGENT_PORT: 9001
      # LOG_LEVEL: debug
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

  portainer:
    image: portainer/portainer
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    ports:
      - "29000:9000"
      - "28000:8000"
    volumes:
      - portainer_data:/data
    networks:
      - server
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.hostname == helder-linux

networks:
  server:

volumes:
  portainer_data:
  jupyterhub_data:
  elasticsearch_data:
  airflow_db:
  db_volume:
  data1-1:
  data1-2:
  data2-1:
  data2-2:
  data3-1:
  data3-2:
  data4-1:
  data4-2:
  nfs-data:
    driver_opts:
      type: "nfs"
      o: "addr=192.168.100.5,rw,sync"
      device: ":/vol"
